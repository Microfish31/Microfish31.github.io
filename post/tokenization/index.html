<!DOCTYPE html>
<html
  dir="ltr"
  lang="en"
  data-theme=""
  
    class="html theme--light"
  
><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <title>
    Microfish
        |
        Tokenization
      

    

  </title>

  
  <meta charset="utf-8" /><meta name="generator" content="Hugo 0.123.7"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
  <meta name="author" content="Microfish" />
  <meta
    name="description"
    content="Love travel , love writing."
  />
  
  
    
    
    <link
      rel="stylesheet"
      href="/scss/main.min.26d8396ded3f4aa47cc8d77a9fcb09fee1d20d223c6b3f074a21c7e217bc8c6d.css"
      integrity="sha256-Jtg5be0/SqR8yNd6n8sJ/uHSDSI8az8HSiHH4he8jG0="
      crossorigin="anonymous"
      type="text/css"
    />
  

  
  <link
    rel="stylesheet"
    href="/css/markupHighlight.min.73ccfdf28df555e11009c13c20ced067af3cb021504cba43644c705930428b00.css"
    integrity="sha256-c8z98o31VeEQCcE8IM7QZ688sCFQTLpDZExwWTBCiwA="
    crossorigin="anonymous"
    type="text/css"
  />
  
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css"
    integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css"
    integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css"
    integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css"
    integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />

  <link rel="canonical" href="http://localhost:1313/post/tokenization/" />

  
  
  
  
  <script
    type="text/javascript"
    src="/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js"
    integrity="sha256-&#43;RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI="
    crossorigin="anonymous"
  ></script>

  
    
    
    <script
      type="text/javascript"
      src="/js/anatole-theme-switcher.min.d6d329d93844b162e8bed1e915619625ca91687952177552b9b3e211014a2957.js"
      integrity="sha256-1tMp2ThEsWLovtHpFWGWJcqRaHlSF3VSubPiEQFKKVc="
      crossorigin="anonymous"
    ></script>
  

  


  
  <meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Tokenization"/>
<meta name="twitter:description" content="Discussion about Tokenization."/>



  
  <meta property="og:title" content="Tokenization" />
<meta property="og:description" content="Discussion about Tokenization." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/post/tokenization/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2024-08-12T02:00:04+00:00" />
<meta property="article:modified_time" content="2024-08-12T02:00:04+00:00" /><meta property="og:site_name" content="Microfish" />




  
  
  
  
  <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "articleSection": "post",
        "name": "Tokenization",
        "headline": "Tokenization",
        "alternativeHeadline": "",
        "description": "
      
        \u003cp\u003eDiscussion about Tokenization.\u003c\/p\u003e


      


    ",
        "inLanguage": "en",
        "isFamilyFriendly": "true",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/localhost:1313\/post\/tokenization\/"
        },
        "author" : {
            "@type": "Person",
            "name": "Microfish"
        },
        "creator" : {
            "@type": "Person",
            "name": "Microfish"
        },
        "accountablePerson" : {
            "@type": "Person",
            "name": "Microfish"
        },
        "copyrightHolder" : {
            "@type": "Person",
            "name": "Microfish"
        },
        "copyrightYear" : "2024",
        "dateCreated": "2024-08-12T02:00:04.00Z",
        "datePublished": "2024-08-12T02:00:04.00Z",
        "dateModified": "2024-08-12T02:00:04.00Z",
        "publisher":{
            "@type":"Organization",
            "name": "Microfish",
            "url": "http://localhost:1313/",
            "logo": {
                "@type": "ImageObject",
                "url": "http:\/\/localhost:1313\/favicon-32x32.png",
                "width":"32",
                "height":"32"
            }
        },
        "image": 
      [
      ]

    ,
        "url" : "http:\/\/localhost:1313\/post\/tokenization\/",
        "wordCount" : "329",
        "genre" : [ ],
        "keywords" : [ ]
    }
  </script>


</head>
<body class="body">
    <div class="wrapper">
      <aside
        
          class="wrapper__sidebar"
        
      ><div
  class="sidebar
    animated fadeInDown
  "
>
  <div class="sidebar__content">
    <div class="sidebar__introduction">
      <img
        class="sidebar__introduction-profileimage"
        src="https://avatars.githubusercontent.com/u/75024370?v=4"
        alt="profile picture"
      />
      
        <div class="sidebar__introduction-title">
          <a href="/">Microfish</a>
        </div>
      
      <div class="sidebar__introduction-description">
        <p>Love travel , love writing.</p>
      </div>
    </div>
    <ul class="sidebar__list">
      
    </ul>
  </div><footer class="footer footer__sidebar">
  <ul class="footer__list">
    <li class="footer__item">
      &copy;
      
        Microfish
        2025
      
    </li>
    
  </ul>
</footer>
  
  <script
    type="text/javascript"
    src="/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js"
    integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ="
    crossorigin="anonymous"
  ></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" integrity="sha384-t5CR&#43;zwDAROtph0PXGte6ia8heboACF9R5l/DiY&#43;WZ3P2lxNgvJkQk5n7GPvLMYw" crossorigin="anonymous" /><script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js" integrity="sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8&#43;w2LAIftJEULZABrF9PPFv&#43;tVkH" crossorigin="anonymous"></script><script
      defer
      src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js"
      integrity="sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB&#43;w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v"
      crossorigin="anonymous"
      onload="renderMathInElement(document.body);"
    ></script></div>
</aside>
      <main
        
          class="wrapper__main"
        
      >
        <header class="header"><div
  class="
    animated fadeInDown
  "
>
  <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
    <span aria-hidden="true" class="navbar-burger__line"></span>
    <span aria-hidden="true" class="navbar-burger__line"></span>
    <span aria-hidden="true" class="navbar-burger__line"></span>
  </a>
  <nav class="nav">
    <ul class="nav__list" id="navMenu">
      
      
        
        
          <li class="nav__list-item">
            
            <a
              
              href="/"
              
              title=""
              >Home</a
            >
          </li>
        

      
        
        
          <li class="nav__list-item">
            
            <a
              
              href="/post/"
              
              title=""
              >Posts</a
            >
          </li>
        

      
        
        
          <li class="nav__list-item">
            
            <a
              
              href="/about/"
              
              title=""
              >About</a
            >
          </li>
        

      
        
        
          <li class="nav__list-item">
            
            <a
              
              href="/portfolio/"
              
              title=""
              >Portfolio</a
            >
          </li>
        

      
        
        
          <li class="nav__list-item">
            
            <a
              
              href="/contact/"
              
              title=""
              >Contact</a
            >
          </li>
        

      
    </ul>
    <ul class="nav__list nav__list--end">
      
      
        <li class="nav__list-item">
          <div class="themeswitch">
            <a title="Switch Theme">
              <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a>
          </div>
        </li>
      
    </ul>
  </nav>
</div>
</header>
  <div
    class="post 
      animated fadeInDown
    "
  >
    
    <div class="post__content">
      <h1>Tokenization</h1>
      
        <ul class="post__meta">
          <li class="post__meta-item">
            <em class="fas fa-calendar-day post__meta-icon"></em>
            <span class="post__meta-text"
              >
                
                  Mon, Aug 12, 2024
                

              
            </span>
          </li>
          <li class="post__meta-item">
            <em class="fas fa-stopwatch post__meta-icon"></em>
            <span class="post__meta-text">2-minute read</span>
          </li>
        </ul>
      <p>Discussion about Tokenization.</p>
<h3 id="introduction">Introduction</h3>
<p><strong>Tokenization</strong> 分詞<br>
<strong>Tokenizer</strong> 分詞器</p>
<ul>
<li>Character Tokenization</li>
<li>Word Tokenization</li>
</ul>
<h2 id="character-tokenization">Character Tokenization</h2>
<h3 id="1-character-tokenization">1. Character Tokenization</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>string <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;How are you?&#34;</span>
</span></span><span style="display:flex;"><span>tokenized_str <span style="color:#f92672">=</span> list(string)
</span></span><span style="display:flex;"><span>print(tokenized_str)
</span></span></code></pre></div><ul>
<li>
<p><strong>Explanation:</strong></p>
<ul>
<li>The string <code>&quot;How are you?&quot;</code> is converted into a list of characters.</li>
<li><code>list(string)</code> splits the string into individual characters.</li>
</ul>
</li>
<li>
<p><strong>Output:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>[<span style="color:#e6db74">&#39;H&#39;</span>, <span style="color:#e6db74">&#39;o&#39;</span>, <span style="color:#e6db74">&#39;w&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, <span style="color:#e6db74">&#39;a&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>, <span style="color:#e6db74">&#39;e&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, <span style="color:#e6db74">&#39;y&#39;</span>, <span style="color:#e6db74">&#39;o&#39;</span>, <span style="color:#e6db74">&#39;u&#39;</span>, <span style="color:#e6db74">&#39;?&#39;</span>]
</span></span></code></pre></div></li>
</ul>
<h3 id="2-numericalization">2. Numericalization</h3>
<h4 id="step-1-remove-duplicates-and-sort-characters">Step 1: Remove Duplicates and Sort Characters</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>unique_chars <span style="color:#f92672">=</span> sorted(set(tokenized_str))
</span></span></code></pre></div><ul>
<li>
<p><strong>Explanation:</strong></p>
<ul>
<li><code>set(tokenized_str)</code> removes duplicate characters, keeping only unique ones.</li>
<li><code>sorted()</code> sorts these unique characters in ascending order (based on ASCII values).</li>
</ul>
</li>
<li>
<p><strong>Example Output:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>[<span style="color:#e6db74">&#39; &#39;</span>, <span style="color:#e6db74">&#39;?&#39;</span>, <span style="color:#e6db74">&#39;H&#39;</span>, <span style="color:#e6db74">&#39;a&#39;</span>, <span style="color:#e6db74">&#39;e&#39;</span>, <span style="color:#e6db74">&#39;o&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>, <span style="color:#e6db74">&#39;u&#39;</span>, <span style="color:#e6db74">&#39;w&#39;</span>, <span style="color:#e6db74">&#39;y&#39;</span>]
</span></span></code></pre></div></li>
</ul>
<h4 id="step-2-assign-a-unique-index-to-each-character">Step 2: Assign a Unique Index to Each Character</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>token2idx <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> idx, ch <span style="color:#f92672">in</span> enumerate(unique_chars):
</span></span><span style="display:flex;"><span>    token2idx[ch] <span style="color:#f92672">=</span> idx
</span></span></code></pre></div><ul>
<li>
<p><strong>Explanation:</strong></p>
<ul>
<li><code>enumerate(unique_chars)</code> assigns an index to each character.</li>
<li>A dictionary <code>token2idx</code> is created where each character is a key, and its index is the corresponding value.</li>
</ul>
</li>
<li>
<p><strong>Example Output:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>{<span style="color:#e6db74">&#39; &#39;</span>: <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#39;?&#39;</span>: <span style="color:#ae81ff">1</span>, <span style="color:#e6db74">&#39;H&#39;</span>: <span style="color:#ae81ff">2</span>, <span style="color:#e6db74">&#39;a&#39;</span>: <span style="color:#ae81ff">3</span>, <span style="color:#e6db74">&#39;e&#39;</span>: <span style="color:#ae81ff">4</span>, <span style="color:#e6db74">&#39;o&#39;</span>: <span style="color:#ae81ff">5</span>, <span style="color:#e6db74">&#39;r&#39;</span>: <span style="color:#ae81ff">6</span>, <span style="color:#e6db74">&#39;u&#39;</span>: <span style="color:#ae81ff">7</span>, <span style="color:#e6db74">&#39;w&#39;</span>: <span style="color:#ae81ff">8</span>, <span style="color:#e6db74">&#39;y&#39;</span>: <span style="color:#ae81ff">9</span>}
</span></span></code></pre></div></li>
</ul>
<h3 id="3-mapping-characters-to-indices">3. Mapping Characters to Indices</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>input_ids <span style="color:#f92672">=</span> [token2idx[token] <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokenized_str]
</span></span><span style="display:flex;"><span>print(input_ids)
</span></span></code></pre></div><ul>
<li>
<p><strong>Explanation:</strong></p>
<ul>
<li>This step maps each character in the original string to its corresponding index from the <code>token2idx</code> dictionary.</li>
<li><code>input_ids</code> will be a list of integers representing the original string.</li>
</ul>
</li>
<li>
<p><strong>Example Output:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">1</span>]
</span></span></code></pre></div></li>
</ul>
<h3 id="summary">Summary:</h3>
<ul>
<li><strong>Character Tokenization:</strong> Converts the string into a list of individual characters.</li>
<li><strong>Numericalization:</strong>
<ol>
<li>Creates a sorted list of unique characters.</li>
<li>Assigns a unique index to each character.</li>
</ol>
</li>
<li><strong>Mapping:</strong> Converts the original string into a list of indices based on the tokenization and numericalization process.</li>
</ul>
<hr>
<h2 id="word-tokenization">Word Tokenization</h2>
<h3 id="1-word-tokenization">1. Word Tokenization</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Word tokenization</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>string <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;How are you?&#34;</span>
</span></span><span style="display:flex;"><span>tokenized_str <span style="color:#f92672">=</span> string<span style="color:#f92672">.</span>split()
</span></span><span style="display:flex;"><span>print(tokenized_str)
</span></span></code></pre></div><h3 id="2-numericalization-1">2. Numericalization</h3>
<p>The same .</p>
<h3 id="3-mapping-characters-to-indices-1">3. Mapping Characters to Indices</h3>
<p>The same.</p>
<h2 id="next----subword-tokenization">Next -  Subword tokenization</h2>
<h3 id="references">References</h3>
<ul>
<li><a href="https://huggingface.co/docs/transformers/main/en/tokenizer_summary">Summary of the tokenizers</a></li>
<li><a href="https://njoroge.tomorrow.co.ke/blog/ai/word_vs_character_level_tokenization">Character vs. Word Tokenization in NLP: Unveiling the Trade-Offs in Model Size, Parameters, and Compute</a></li>
</ul></div>
    <div class="post__footer">
      

      
    </div>

    <div id="comment">
          <h2>comments</h2>
          <div id="commento"></div>
<script defer src="https://cdn.commento.io/js/commento.js"></script>
<noscript>Please enable JavaScript to load the comments.</noscript>

        </div>
  </div>

      </main>
    </div><footer class="footer footer__base">
  <ul class="footer__list">
    <li class="footer__item">
      &copy;
      
        Microfish
        2025
      
    </li>
    
  </ul>
</footer>
  
  <script
    type="text/javascript"
    src="/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js"
    integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ="
    crossorigin="anonymous"
  ></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" integrity="sha384-t5CR&#43;zwDAROtph0PXGte6ia8heboACF9R5l/DiY&#43;WZ3P2lxNgvJkQk5n7GPvLMYw" crossorigin="anonymous" /><script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js" integrity="sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8&#43;w2LAIftJEULZABrF9PPFv&#43;tVkH" crossorigin="anonymous"></script><script
      defer
      src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js"
      integrity="sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB&#43;w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v"
      crossorigin="anonymous"
      onload="renderMathInElement(document.body);"
    ></script></body>
</html>

<script src="https://unpkg.com/mermaid@8.13.4/dist/mermaid.min.js"></script>
<script>
  mermaid.initialize({ startOnLoad: true });
</script>